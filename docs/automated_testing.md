---
id: automated_testing
title: Automated Integrated Testing
sidebar_label: Automated Testing
slug: /automated_integrated_testing
---

<!-- original: https://docs.google.com/document/d/1hkNr78mrU3Ha98tPUL4OKWi3eNnt-1Sba7L8470u06g/edit# -->

🚧 Reference for writing automated integrated tests with the Assembly Line testing framework.

<!-- ## Setup

Talk to us about it.
-->

## Summary

1. You write and edit `.feature` test files in your Sources folder.
1. There's a maximum of 2 minutes per individual Step or table row. That can't be customized yet.
1. Tests are run when you commit.
1. Tests can download PDF files, but humans have to review them to see if they're right.
1. Tests that error should create screenshots from when the error happened.
1. Tests create report files. They don't have a lot right now, but they might have some clues when something unexpected happens.

For interacting with things on GitHub, look for how to use the 'Actions' tab.

## Example

The tests use the [gherkin language and syntax](https://cucumber.io/docs/gherkin/reference/). Here's a complex example for quick reference of some of our features:

```
@children
Feature: The user has children

  @fast @child_benefits
  Scenario: child has benefits
    Given I start the interview at "some_file_name"
    And I get to the question id "benefits" with this data:
      | var | value | trigger |
      | x[i].name.first | Cashmere | children[0].name.first |
      | x[i].name.first | Casey | children[1].name.first |
      | x.there_are_any | True | children.there_are_any |
      | x.there_is_another | 2 | children.there_is_another |
    When I set the var "benefits['SSI']" to "true"
    And I tap to continue
    Then the question id should be "download"
    And I download "some_motion.pdf"

```

## Story tables syntax

Very basically, a **story table** contains a list of variables and values. The order in which they appear does not matter, which gives a lot more flexibility when developers are changing around the order of questions.

Tip: it can be easy to lose track of what variables you've included, so it can be useful keep the rows in alphabetical order.

### Story table description

The step that triggers a story table is

```
    And I get to the question id "some id!" with this data:
```

Under that, you put the header row of the table:

```
      | var | value | trigger |
```

Under that, you add a row for every field that you want to interact with during the interview. Start with a blank row then fill it in:
```
      |  |  |  |
```

### var

In the **var** column, write the name of the variable you want to set **as it appears on question's screen**. Most times you can see that value in the YAML `question` block. Sometimes it will be generated by code in the `question` block. If you're not sure what name some code generates, you may have to ask the folks who wrote the code.

<!-- The Document Assembly Line library has built in questions that use such code.
- `users[i].name_fields()` generates all the name fields with the right index number (NOT 'i'). E.g. `users[0].name.first`, `users[0].name.suffix`, `users[1].name.first`, `users[1].name.suffix`
- `users[i].address_fields()` generates all the address fields with the right index number (NOT 'i'). E.g. `users[0].address.address`, `users[1].address.address` -->

### value

In the **value** column, write what you want the field to be set to. For checkboxes, `true` means 'checked' and `false` means 'unchecked'.


### trigger

In the **trigger** column, write the name of the intrinsic name of the variable that will trigger the page for this field. This column is optional in most cases. In cases where the page is using an [index variable](https://docassemble.org/docs/fields.html#index%20variables) or a [`generic object`](https://docassemble.org/docs/modifiers.html#generic%20object).


### Story table examples

Simple field types with their values

[yesno buttons](https://docassemble.org/docs/fields.html#yesno), [yesnoradio](https://docassemble.org/docs/fields.html#fields%20yesno) choice 'yes', etc.
```
      | has_hair | True | has_hair |
```

[yesnomaybe buttons](https://docassemble.org/docs/fields.html#yesnomaybe) or [datatype: yesnomaybe](https://docassemble.org/docs/fields.html#fields%20yesno) choice 'maybe'
```
      | has_hair | None | has_hair |
```

Checkboxes with multiple choices
```
      | benefits['SSI'] | true | benefits |
```

Radio or dropdown choices
```
      | favorite_color | green | favorite_color |
```

Text field or textarea
```
      | favorite_color | Blue.\nNo, green!\nAaah... | favorite_color |
```

A generic object with an index variable. The `trigger` column is required here
```
      | x[i].name.first | Umi | users[1].name.first |
```

### `.there_is_another` loop

This special row's `value` should be the number of items that this interview will have. The below row will tell the test that you will create three users.

```
      | x.there_is_another | 3 | users.there_is_another |
```

You will still need to add the rows for the information for all three `users`.
```
      | x[i].name.first | Umi | users[0].name.first |
      | x[i].name.first | Ulli | users[1].name.first |
      | x[i].name.first | Ulla | users[2].name.first |
```

### Story table signature

The `value` for a row setting a signature doesn't matter. All signatures will be a dot.
```
      | user.signature |  | user.signature |
```

### Other notes

Don't worry about accidentally including variables that won't show up during the test. They'll just be ignored.


## Steps

You can use the [steps](https://cucumber.io/docs/gherkin/reference/#steps) below (listed in aphabetical order):

### Starting Step

Leave out the extension of the file. Use just the name by itself.
```
    Given I start the interview at "yaml_file_name"
```
<!-- And I am using a mobile -->

### Observe things about the page

To check the id, look at the YAML `question` block and copy the id from there. Adding this Step into the code of the test can help you, as a human, keep track of what fields you should be filling in next.
```
    Then the question id should be "some yaml block id!"
```
```
    Then I can't continue
```
```
    Then I will be told an answer is invalid
```
```
    Then I arrive at the next page
```

Screenshots will be in the GitHub action's 'artifacts'.
<!-- And I take a screenshot ?(?:named "([^"]+)")? -->
```
    Then I take a screenshot
```
```
    Then I should see the link to "a-url.com"
```

<!-- Then an element should have the id "some_HTML_element_id" -->

Checking phrases will be language specific. Also, docassemble sometimes uses some weird characters on screen, so copying it straight from the screen is best.
```
    Then I SHOULD see the phrase "some phrase"
```
```
    Then I should NOT see the phrase "some phrase"
```

<!-- Then the "a" link leads to "a" -->
<!-- Then the "a" link opens a working page -->
<!-- Then the "a" link opens in a new window -->
<!-- Then the "a" link opens in the same window -->


### Set fields

```
    When I tap to continue
```

Set most fields like this
```
    When I set the variable "users[i].hair_color" to "blue"
```

Sign on a signature field. All signatures are the same.
```
    When I sign
```

Specifically for the Document Assembly Line four-part name questions. No punctuation.
```
    When I set the name of "x[i]" to "Ulli User"
```

Specifically for the Document Assembly Line address questions. 
<!-- Get Tremont address "112 Southampton St., Unit 1, Boston, MA 02118" -->
```
    When I set the address of "users[0]" to "______"
```

The Step for the story table, which is better described in sections above.
```
I get to the question id "some yml block id" with this data:
```

### Other actions

```
    When I tap to continue
```

Documents will be in the GitHub action's 'artifacts'.
```
    Then I download "file-name.pdf"
```

You can give this any number of seconds, though all Steps will timeout after two minutes.
```
    When I wait 10 seconds
```

<!-- When I tap the defined text link {string} -->
<!-- When I do nothing -->


## Test instructions details

### Add a new test

Go to your Playground > the dropdown Folders menu > Sources.

Add a new file that ends in the extension `.feature`. Ex: `has_children.feature`

The next time you commit, your test will be run. You can add and edit multiple test files.

### When do tests run?

Tests run when you commit your files to GitHub. That might be when you hit the 'Commit' button on the Packages page. It can also happen when you edit, add, or delete files in GitHub itself.

If you know how to use GitHub actions, you can also run the tests manually from GitHub actions with some more options.

### Scenario descriptions

These affect the names of error screenshot files and such things, so try to use useful descriptions.

<!-- 

Don’t worry if you accidentally put an extra value in a column that is not a required column for that field-type. It should work just fine. It might be a little confusing for you to look at later when you don’t remember what you were doing, though.

Extra variables in the table also are not a problem. You can have as many extra rows as you want and it won’t get in the way of testing with stories/tables.


### Special story table rows 
{#special-story-table-rows}


```
WARNING: As of 2021/01/17 these tests can only handle ONE SIGNATURE ROW per 'story' table. Sorry about that, folks. See Github issue.
```



#### Signing 
{#signing}

For a signature page, use a signature row:


```
    ||| /sign |
```


Signing cannot be set for any specific variable or in any particular order. After running into a signature page, a signature row will be used up. If your interview has 3 signatures, you need 3 signature rows.


```
Feature: Signatures all the way down
Scenario: This interview only has signatures, but it has three of them.
  Given I start the interview at "my_interview_YAML_file_name"
  And the user gets to the question id "admit_to_ward" with the data:
    | var | choice | value |
    ||| /sign |
    ||| /sign |
    ||| /sign |
```



### Other **Steps** you can use 
{#other-steps-you-can-use}

**Steps** here can work in multiple languages unless there’s a note that says they can’t. Stuff in double quotes can be whatever you want it to be.


#### General-use sentences 
{#general-use-sentences}


   **Step sentence**
   **More info**
   Given I start the interview at "z"
   "z" is the name of the YAML file you run when you start the interview.
   And I take a screenshot named "z"

Or

And I take a screenshot
   A way to try to troubleshoot. Images created like this will be in the <a href="https://docs.github.com/en/free-pro-team@latest/actions/managing-workflow-runs/downloading-workflow-artifacts">Github ‘artifacts’</a> of the <a href="https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/introduction-to-github-actions#viewing-the-jobs-activity">action</a> after the tests finish. This testing framework gives each screenshot a unique name, so you can take as many as you want.
   And I wait 2 seconds
   "2" can be any number under 120. You can use it to give something time to load. If you want to wait longer, you can add two or three of these **Steps** in a row. It only works in between other **Steps** as a separate **Step** - it is unable to extend a previous **Step**. We’re working on how to let the developer add extra-long wait times to some **Steps**.
   I download "z.zip"
   “z.zip” can be any file name with any extension. It should be a page element that the user can click on to download something. Files created like this will be in the <a href="https://docs.github.com/en/free-pro-team@latest/actions/managing-workflow-runs/downloading-workflow-artifacts">Github test ‘artifacts’</a> of the <a href="https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/introduction-to-github-actions#viewing-the-jobs-activity">action</a> after the tests finish. It should not take more than 2 minutes to download. We plan to make that more flexible later if this framework seems useful to people.
   Then I will be told an answer is invalid
   Checks that some kind of message is visible on the page telling the user that their answer was invalid.
   Then the "z.com" link opens a working page
   "z.com" can be any address. Checks that the link is on the page and that it leads to a working page. This can be a way to check that something like an ‘Escape’ link is working.
   And I am using a mobile/pc
   Not as fancy as you think. There are some features that simulate a phone, but we think it is not fully featured. For headers used, see the <a href="#bookmark=id.9wdh1mwnt9uu">Specs section</a>. Yeah, this says ‘I’ instead of ‘user’. We’re not paragons of consistency… yet…



#### Very controlled test **Steps** 
{#very-controlled-test-steps}

These are usually not useful, but might help if you need to get very fine-grained with the behavior of the test. Some of them are very limited in their use.


   **Step sentence**
   **More info**
   When I tap to continue
   For ‘continue’ buttons that don’t have a variable name
   Then the question id should be "z"
   "z" is the id of the question. This can help print useful errors to the console when something goes wrong and helps keep track in your code.
   Then I arrive at the next page
   Checks the url of the page has changed. For example, the user was able to continue.
   Then I can't continue
   Checks that the url is the same since the last **Step**. You can test whether the interview correctly stopped a user from going on when they hadn’t filled in enough information and other such things.
   Then I SHOULD see the phrase "z"
   ONLY WORKS IN ONE LANGUAGE. Will not work to test translations.
   Then I should NOT see the phrase "z"
   ONLY WORKS IN ONE LANGUAGE. Will not work to test translations.
   And I set the name of "users[0]" to "Uli Ula Ulther III"
   For the variable name given, this fills in an AssemblyLine 4-field name question with the 4-part name given. The name suffixes are limited to certain choices. See AssemblyLine files.
   And I set the address of the var "tenant" to "112 Southampton St., Unit 1, Boston, MA 02118"
   For the variable name given, this fills in an AssemblyLine 5-field address question with the 5-part address given. It can be any address you want that matches the format shown, commas and all. See AssemblyLine files.



### Specs 
{#specs}


#### Devices 
{#devices}

Not as fancy as you might want. Uses some features, but we’re not sure how fully featured it is.

**mobile:** Mozilla/5.0 (Linux; Android 8.0.0; SM-G960F Build/R16NW) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.84 Mobile Safari/537.36

**pc:** Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3312.0 Safari/537.36




## Set up testing for your repo (todo) 
{#set-up-testing-for-your-repo-todo}



1. Add [SECRETS](https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository) based on an account that is on the server you will be testing. Copy then **Name** exactly as you see it here:

   
**Name**
   **Value**
   PLAYGROUND_EMAIL
   email used to log into that account
   PLAYGROUND_PASSWORD
   password used to log into that account
   PLAYGROUND_ID
   To see this, log into that account and run an interview in the playground. Look at the URL. It will have this anatomy:

<a href="https://some-server.org/interview?i=docassemble.playground1234ProjectName%3Afile_name.yml">https://some-server.org/interview?i=docassemble.playground1234ProjectName%3Afile_name.yml</a>

“1234” is the spot where you will find your id. See what number yours is and type that as the value.




2. Contact someone from the [testing repo](https://github.com/plocket/docassemble-cucumber). Either:
    1. Give them permissions to push to a new branch on your repository or
    2. Make a new branch on your repo for adding this testing framework. Copy the files you are told to. Edit the file in the way you are told. Commit those files. You should end up with these additional files and folders:
        1. testing/features/example.feature
        2. .github/workflow/run_form_tests.yml
        3. package.json
        4. .gitignore
3. Merge that branch into your default branch (usually main or master)
4. [You can now see the tests running](https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/introduction-to-github-actions#viewing-the-jobs-activity).

If you’re only editing in GitHub you can start writing your tests and committing them to see how they go.

If you’re writing your tests locally, you will need to make a .env file that will have those same environment variables in them. Your .env file should look like this:


## Create a test 
{#create-a-test}


### Create a test file 
{#create-a-test-file}



1. Either [in GitHub](https://docs.github.com/en/github/managing-files-in-a-repository/editing-files-in-your-repository) or in your own editor, open the folder ‘tests/features’
2. Make a new file.
3. Add this code:

    ```
Feature: Feature description

To add:
[ ] Child HAS a guardian ad litem
[ ] Child does NOT have a guardian ad litem


```


4. Replace ‘Feature description’ with a description of the purpose of the tests in this file.
5. Delete the text under that or replace it with notes you have. The example shows how you can add a checklist of situations you might want to remember to cover in here.
6. Name the file. Example: 1_child.feature
    1. Always end the file with ‘.feature’.
    2. Use a descriptive name.
7. Add **Scenarios** or **Examples** to the file (see how you can [generate an interview Scenario from a completed interview](#bookmark=id.8qqq5w9ws641) below)
8. [Save/commit the file with a commit message](https://docs.github.com/en/github/managing-files-in-a-repository/editing-files-in-your-repository). Something like ‘Add examples for a parent with one child’
9. [Check to see if your code passes or not](https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions#viewing-the-jobs-activity).


### Generate code from an interview 
{#generate-code-from-an-interview}

Generate one ‘story table’ in an **Example** or **Scenario**: [https://repl.it/@plocket/generatetestsfromobj#index.js](https://repl.it/@plocket/generatetestsfromobj#index.js)


#### Generate the code 
{#generate-the-code}



1. Decide on the values and branching path that you want to be able to automatically test in the future.
2. Go through your interview following that path and with those values all the way to the page you want to end on.
3. Take note of the question **id** on the final page.
4. Tap the ‘Sources’ link in the header of that final page.
5. Tap on the ‘Show all variables and values’ link just under the ‘Readability’ chart.
6. Select and copy all the contents on that page
    1. Mac: `cmd + a` then` cmd + c`
    2. PC: `ctrl + a` then `ctrl + c`
7. [Tap this link](https://repl.it/@plocket/generatetestsfromobj#da_data.json)
8. WARNING: IF YOU LEAVE THIS PAGE your changes will not be saved.
9. After the next step, a popup will appear. Just hit the ‘x’ in the circle outside the box on the top right.
10. Select all the text on that page and then paste what you copied from the variables and values page.
    3. Mac: `cmd + a` then` cmd + v`
    4. PC: `ctrl + a` then `ctrl + v`
11. You’ll see the pop up asking you to join. Just close it by hitting the ‘x’ in the circle outside the box on the top right.
12. In the left column, click on ‘index.js’
13. In the header, click on the ‘Run’ button. It should be near the center.
14. Copy the output that will show up in the ‘output’ column on the right.
15. Paste that text into your test file somewhere under the **Feature:** description.
16. Change the fake description of the **Scenario** to describe what will be specifically covered by this story.
17. Change the fake question id to be the real question id of that final page.
18. Change the fake YAML file name to be the actual name of the YAML file that starts your interview.
19. [Save/commit the file](https://docs.github.com/en/github/managing-files-in-a-repository/editing-files-in-your-repository).
20. [Check to see if your code passes or not](https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions#viewing-the-jobs-activity).


#### Generating data again using the same repl.it page 
{#generating-data-again-using-the-same-repl-it-page}

If you already ran the code once and there is still output text in the column on the right, make sure you hit the hard-to-see gray ‘delete’ or ‘x’ button in the top right of the ‘output’ column on the right.


#### Make new tests from that code 
{#make-new-tests-from-that-code}



1. Copy the code of the **Scenario** or **Example**.
2. Move to above that **Scenario** or **Example** or below the bottom of the whole **Scenario** or **Example**.
3. Delete the **Scenario** or **Example** description.
4. Add ‘TODO: ‘ to the description, then the text that describes what you will test.
5. Change the values of the variables that need changing.
6. When you’re done, remove the ‘TODO: ‘ from the **Scenario** or **Example** description.
7. [Save/commit the file](https://docs.github.com/en/github/managing-files-in-a-repository/editing-files-in-your-repository).
8. [Check to see if your code passes or not](https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions#viewing-the-jobs-activity).




## Failing tests 
{#failing-tests}

Look at the [results of your tests](https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/introduction-to-github-actions#viewing-the-jobs-activity). Some of the error messages may tell you more. Also download the [Github test ‘artifacts’](https://docs.github.com/en/free-pro-team@latest/actions/managing-workflow-runs/downloading-workflow-artifacts) and see if any of those files give you a clue.


### The tests fail at the very first Step 
{#the-tests-fail-at-the-very-first-step}



1. Check the ‘Run npm run setup’ line right above the failed tests. Click to expand it and make sure that setting up the interview didn’t fail. If it did, try running it again.
2. Manually [make a new Project](https://docs.google.com/document/d/1pj1DFIhzzwB6raeCytnmPSR41WfNvG-T9GYPsf1wOsA/edit#heading=h.8yw6hi5hgw1d) on the server and [pull the code](https://docs.google.com/document/d/1pj1DFIhzzwB6raeCytnmPSR41WfNvG-T9GYPsf1wOsA/edit#heading=h.yve8jwod1owz) from the exact same branch into that Project. Manually run the file that is named in your test and double check that it is working the way you expect it to.
3. Make sure that the file you named in your `Given` **Step** is the right file.
4. Have you changed the server where you were running your code? Check your repository’s code in the .github/workflows/run_form_tests.yml file. Make sure the `BASE_URL` in there is the correct one for your server. [Edit it](https://docs.github.com/en/free-pro-team@latest/github/managing-files-in-a-repository/editing-files-in-your-repository) if it is the wrong one.
5. Contact someone who might know more.


### Two tests on the same branch failed at the same time 
{#two-tests-on-the-same-branch-failed-at-the-same-time}

IF YOU TRIGGER TWO TESTS ON THE SAME BRANCH VERY CLOSE TOGETHER, both tests might fail. You’ll have to rerun the tests. When you’ve pushed/committed, try to wait until one test has finished running before pushing/committing again. You can see [when a test has finished running on the actions page](https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/introduction-to-github-actions#viewing-the-jobs-activity). You can also[ cancel a test](https://docs.github.com/en/free-pro-team@latest/actions/managing-workflow-runs/canceling-a-workflow).

If we see that people are finding this framework useful, we can improve on that.


### The test failed on or after ‘upload error artifacts’ 
{#the-test-failed-on-or-after-‘upload-error-artifacts’}

Something probably went wrong with Github. Or maybe they have a maximum amount that they can download that we haven’t yet dug up in their documentation. Try rerunning the tests and, if it fails the same way a second time, get in touch with us.


### The error says it “timed out“ 
{#the-error-says-it-“timed-out“}

That’s a stock system error. Some **Step** took too long to finish in a way for which we have not yet created a custom error message or cannot detect. It is often a page that took too long to load. It sometimes happens when the Project got deleted in the middle of the test, or when the [`Run npm run setup` phase doesn’t work correctly](#bookmark=id.y1ibk27fo4jy).


### Some other mysterious error 
{#some-other-mysterious-error}



1. You can rerun the test
2. Try to search for the text of the error online (don’t spend more than 20 min on this, though)
3. Ask one of us. Remember that this framework is under development. Something might be wrong with our code.




## Cucumber keywords we use 
{#cucumber-keywords-we-use}

We are using a library called cucumber. It is based on a library called gherkin.


### We are doing it wrong. On purpose. 
{#we-are-doing-it-wrong-on-purpose}

We are NOT using cucumber as intended. We do some things a little differently. We will try to let you know which ones.

Cucumber’s main purpose is to make it easier to discuss the behavior of a tool with non-coders so everyone can understand what is supposed to happen. Cucumber specifications are supposed to show the big picture. They are supposed to be written for one specific project. Usually, the coders would write complex and specific code so that the specifications (**Steps**) that people read can give a really quick, clear picture of what is going on.

Usually the **code is specific and the Steps are general.**

For example, they might want to be able to write this sentence:


```
  When a mother with three children wants her address impounded
```


We are not writing specifications for a single interview, though. We also are not writing specifications that show the big picture.

We are writing a _testing_ framework that can be used with every docassemble interview. We flip things a bit.

For us our **code has to be general and the Steps are specific.**


```
  When I tap to continue
```



### `Feature` 
{#`feature`}

It is generally best to use documentation that a library creates for itself so that it stays up-to-date: [https://cucumber.io/docs/gherkin/reference/#feature](https://cucumber.io/docs/gherkin/reference/#feature). Let us know if we should add more information.


### `Scenario`/`Example` 
{#`scenario`-`example`}

It is generally best to use documentation that a library creates for itself so that it stays up-to-date: [https://cucumber.io/docs/gherkin/reference/#example](https://cucumber.io/docs/gherkin/reference/#example). Let us know if we should add more information.

What we do differently:

We often use many more than 3 to 5 **Steps** in a **Scenario** or **Example**. [Like we said before](#bookmark=id.lm0ajwvdd3es), because we’re building a testing framework, our **Steps** are much more specific.


### `Step` keywords 
{#`step`-keywords}

We use these **Step** keywords: ‘Given’, ‘And’, ‘When’, and ‘Then’.

It is generally best to use documentation that a library creates for itself so that it stays up-to-date: [https://cucumber.io/docs/gherkin/reference/#steps](https://cucumber.io/docs/gherkin/reference/#steps). Let us know if we should add more information.

What we do differently:

You can repeat **Steps** any time during a **Scenario**. Just write what the test should do. Something like this will work just fine:


```
  And I wait 30 seconds
  And I wait 10 seconds
```





## Types of tests 
{#types-of-tests}


### Make sure user cannot continue (story tables) 
{#make-sure-user-cannot-continue-story-tables}

A story table won’t work 




## Story Tables (todo) 
{#story-tables-todo}

More details about what ‘story tables’ are and how they work




## **Steps** 
{#steps}

A **Step** is one instruction that you can give to the test. Each of these steps is something we’ve programmed specifically for docassemble tests.

It is generally best to use documentation that a library creates for itself so that it stays up-to-date: [https://cucumber.io/docs/gherkin/reference/#steps](https://cucumber.io/docs/gherkin/reference/#steps). Let us know if we should add more information.


### What a **Step** looks like 
{#what-a-step-looks-like}

Step syntax.

**Steps** come after their **Scenario:** row and are indented one level more than their **Scenario:** row. You have to start each **Step** with ‘Given’, ‘And’, ‘When’, or ‘Then’. Those words are interchangeable - you can use whichever one you want. 

Each **Step** is a sentence. Sometimes a **Step** has more information right under it, like with our story tables. That information is still part of the same step. In this example there are three steps and the indentation for each **Step** has been highlighted in green:


```
Feature: A description of the purpose of the tests in this file.
Scenario: A description of what's being specifically tested in this example.
  Given I start the interview at "my_interview_YAML_file_name"
  And the user gets to the question id "admit_to_ward" with the data:
    | var | choice | value |
    | False | has_ears | true |
    | hair_color | blue | true |
    | foot_types | None of the above | true |
    ||| /sign |
  When I download "my_zip.zip"
```


The **Steps** are:



1. The line that starts with ‘Given’
2. The line that starts with ‘And’ which has a table in it
3. The line that starts with ‘When’

**Steps** CANNOT BE MIXED with each other. That is, an error will be caused if a story table **Step** has another **Step** inside it. This will cause an error:


```
Feature: A description of the purpose of this file.
Scenario: A description of what's being specifically tested in this example.
  Given I start the interview at "my_interview_YAML_file_name"
  And the user gets to the question id "page_4_id" with the data:
    | var | choice | value |
    | False | has_ears | true |
    | hair_color | blue | true |
  And I wait 20 seconds
    | foot_types | None of the above | true |
  When I download "my_zip.zip"
```


_(Why `page_id_4?` Because you started on page 1, you went up to page 3, then the ALKiln automatically tapped to continue. We can consider changing it if it becomes a common problem.)_

You might be able to do something like this instead:


```
Feature: A description of the purpose of this file.
Scenario: A description of what's being specifically tested in this example.
  Given I start the interview at "my_interview_YAML_file_name"
  And the user gets to the question id "page_2_id" with the data:
    | var | choice | value |
    | False | has_ears | true |
  When I set the "blue" choice of var "hair_color" to "true"
  And I tap to continue
  And I wait 20 seconds
  And the user gets to the question id "page_4_id" with the data:
    | foot_types | None of the above | true |
  When I download "my_zip.zip"
```





## Translation testing 
{#translation-testing}

A lot of **Steps** are language agnostic. That is, they don’t care about the language in your interview.


### WATCH OUT! 
{#watch-out}

Always give your `choices` values that are separate from their labels.

In docassemble, you can write `choices` a couple of different ways.

Bad


```
question: |
  What is your favorite color?
fields:
  - Colors: favorite_color
    input type: radio
    choices:
      - green
      - red
      - blue
```


Good


```
question: |
  What is your favorite color?
fields:
  - Colors: favorite_color
    input type: radio
    choices:
      - green: green
      - red: red
      - blue: blue
```


If your field is like the Bad example, the label of a choice is also its value and the translations will break the tests. This is because the label will be translated. Since the label is also the value, the value in the translated version of the interview will be different than the value you wrote in for your test.

If your field is like the Good example, the value of the choice should never get translated so it should always be the same and the tests will be happy.


### How to know if a **Step** is language agnostic 
{#how-to-know-if-a-step-is-language-agnostic}

A **Step** can work for any language as long as it does not depend on a word that will be translated. For example, if it:



1. Uses a variable name to set the value. Watch out for [special cases](#bookmark=id.3b9fid1tlalm).
2. Does not use a word on the screen at all. Example: And I wait for 1 second
3. Is only dependant on a word that is inside an element and never gets translated, like a link address or file name: And I download “my_file.zip”
-->


<!-- I think this info is useful, but I'm not sure where it should go.
## About writing tests

**Who?**

It is easier to write the tests if you have access to the YAML code and can understand a bit about docassemble.

**What?**

There are a couple kinds of tests you can write.

You can write a really simple test right away that just makes sure your a file runs using the name of the file. Write a `Scenario` for each file you want to test.

```
Feature: Interviews load

  Scenario: The 209A loads
    Given I start the interview at "ma_209a_package"

  Scenario: The Plaintiff's Motion to Modify loads
    Given I start the interview at "plaintiffs_motion_to_modify_209a"
```

More complex tests might wait till your code is pretty much how you want it. Every time you change your variable names, you may have to update the tests.

**Where?**

The Sources folder. (Go to your Playground > the dropdown Folders menu > Sources.)

**When?**

Write the simple test described above as soon as you want. For the rest, write most of the tests after your code is mostly stable - you don't plan to change the variables that much.

**Why?**

Right now we're focused on two things:

1. The interview runs.
1. The interview keeps working when superficial things about it change. Things like changing the order of questions, the language, or adding translations.
-->

<!-- 
## Open questions

We're interested in hearing your thoughts about these questions in particular.

What kinds of tests would be useful?

What kinds of tests can we provide?

Who are the main users of the testing framework?

-->

## Built with

It uses cucumber, puppeteerjs, cheerio, and runs the assertions using mocha and chai.

Even though this is built off of [cucumber](https://cucumber.io/), this framework has a different, less lofty, purpose. cucumber focuses on BDD (behavior driven development). This framework mostly deals with regression testing and other conveniences.

## Repositories

The framework is at https://github.com/plocket/docassemble-cucumber.

The interview for setting up tets for a repo is at https://apps-dev.suffolklitlab.org/start/test-setup/. It can only set up repository-specific secrets right now. The repo for that interview is at https://github.com/plocket/docassemble-ALAutomatedTestingTests.

The repo for the interviews for testing the framework is also at https://github.com/plocket/docassemble-ALAutomatedTestingTests.
